{"cells":[{"cell_type":"markdown","metadata":{"id":"3250C7AVk641"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/054_pytorch_save/pytorch_save.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"wXnmx7U3k644"},"source":["# Pytorch - Guardando y Exportando Modelos"]},{"cell_type":"markdown","metadata":{"id":"fKBuABZuk644"},"source":["En posts anteriores hemos aprendido a utilizar la librería [Pytorch](https://pytorch.org/), viendo los [conceptos baśicos](https://sensioai.com/blog/027_pytorch_intro), cómo diseñar y entrenar [redes neuroanles](https://sensioai.com/blog/028_pytorch_nn) y a manejar [datasets](https://sensioai.com/blog/029_pytorch_datasets) de manera eficiente. Sin embargo, entrenar un modelo es solo parte del trabajo. Una vez tenemos nuestra red lista necesitamos poder guardarla en un archivo, o exportarla, para luego importarla en nuestras aplicaciones y ponerla a trabajar en un entorno de [producción](https://sensioai.com/blog/052_produccion). En este post vamos a ver las diferentes opciones que `Pytorch` nos ofrece a a la hora de exportar modelos. "]},{"cell_type":"markdown","metadata":{"id":"4f8eEkPMk645"},"source":["## Guardando modelos"]},{"cell_type":"markdown","metadata":{"id":"QMpaFCORk645"},"source":["### Guardando los parámetros"]},{"cell_type":"markdown","metadata":{"id":"PCiOnGUYk645"},"source":["La primera opción consiste en guardar sólo los parámetros de la red. Para ello, `Pytorch` nos permite guardar el `state_dict` del modelo, un `dict` de `Python` que contiene una relación directa entre todas las capas con parámetros de la red y sus valores. \n","\n","En el siguiente código, utilizado ya en [este](https://sensioai.com/blog/042_cnns) post, entrenamos un modelo simple con el dataset `MNIST` y, una vez entrenado, guardamos el `state_dict` del modelo."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-rwJhm2rk646","outputId":"bd75ea0f-d1ee-4b71-c420-ccc97c1290c2","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1678301461707,"user_tz":240,"elapsed":802,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"9RI-FSbJk647","colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["b93f5c7df2444090bfeb743ddbbf3ff2","3915d1941ec34b41b37b774737941fd4","d0df0e2b45554cce9f4362498e346a53","e5e88f4ba889485485af91ef0281f025","5a95aca3df444c668e5d04a1980de689","691e399985bf4792a3d48fb019292b08","ec25cd0f29074671b804132807bec6be","310c76f184c84ab78c5d43412bf0a840","7cb4dc1fe90f4f2597c5e7e20a71fd6c","bd3c0f687e87446584a6b238e87c9fc8","d5ad3707c4984df2920c2edc9006ff4f","6d16cb0d205a4b44b88d24a8d01966cd","c94a2b7b36794e239392f74bfff37515","1c86f865fcbd40a5b64d1eef1654ebec","241e348a98a947fe9fae9b16dcae5ca6","64e7983f7b2b47879fb557e958a0d03f","b035fb6e5e7841a4a81dfa479c5e8260","fd245234912d4158b585d09d7ace1740","b5556b81b8d5473f80fb9b25238e171b","dd0515fc5fc043d684946214652f2472","0bc3c16df03e498fa406784851aeb591","650ae2c78d4e4bb99d22e13dc0be97f4","b7e41746d3e84ec28444cc6a6cf459bd","d368b9a233624fc79239669f0a15120a","a2b54c7c3edf4a36831302f7dea7345a","a3fe87b624dd4883b5ca3944bb048ddf","c124a1fbccce42e5a75c156698a02044","34df469c068a483b94a897e4ec85c034","e901ddfd4b9c4d13802377c61ade63b2","431f621c1cb948efbcc8efc0a5d27811","95dd4dc4a1254bd3bc29e5053bd85574","f02074f2e54e43dca1d21a96d12a5c88","7c46ac524d2f46ca88e362551eb24b0e","ccd9379b10374ce487d4d4e281c95cd0","b53dc7c0083142d0a8d80d2a7cc29bca","669eafef82c547858ef880b17e668ed8","f34ad34c90244d238f98513fbba5f76e","93ba84c075144a64a1a513dd372bd752","e8464eb1c31b44b08acf2375260fb4e6","6f640510e32a4559a61c939130fd1324","fcd8b6d4979d4d60901e87f873f85a3e","25b5e4e4cd964ea59ecbb3673713dc31","c739f662c0884d46bd1c7d56168501d6","582badc8f3864563b8f18c3b239483dc"]},"executionInfo":{"status":"ok","timestamp":1678301467477,"user_tz":240,"elapsed":2339,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}},"outputId":"a313f763-4856-4e99-b19c-9ac3db7816cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93f5c7df2444090bfeb743ddbbf3ff2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d16cb0d205a4b44b88d24a8d01966cd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e41746d3e84ec28444cc6a6cf459bd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd9379b10374ce487d4d4e281c95cd0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n"]}],"source":["# preparamos los datos\n","\n","dataloader = {\n","    'train': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n","                       transform=torchvision.transforms.Compose([\n","                            torchvision.transforms.ToTensor(),\n","                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n","                            ])\n","                      ), batch_size=2048, shuffle=True, pin_memory=True),\n","    'test': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=False,\n","                   transform=torchvision.transforms.Compose([\n","                        torchvision.transforms.ToTensor(),\n","                        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n","                        ])\n","                     ), batch_size=2048, shuffle=False, pin_memory=True)\n","}"]},{"cell_type":"code","execution_count":4,"metadata":{"code_folding":[],"id":"Es23xeO9k647","executionInfo":{"status":"ok","timestamp":1678301482362,"user_tz":240,"elapsed":948,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}}},"outputs":[],"source":["# definimos el modelo\n","\n","def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n","    return torch.nn.Sequential(\n","        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(pk, stride=ps)\n","    )\n","\n","class CNN(torch.nn.Module):\n","  def __init__(self, n_channels=1, n_outputs=10):\n","    super().__init__()\n","    self.conv1 = block(n_channels, 64)\n","    self.conv2 = block(64, 128)\n","    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = x.view(x.shape[0], -1)\n","    x = self.fc(x)\n","    return x"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Kl_694yVk648","executionInfo":{"status":"ok","timestamp":1678301502273,"user_tz":240,"elapsed":4,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}}},"outputs":[],"source":["# entrenamos el modelo\n","\n","def fit(model, dataloader, epochs=5):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","        bar = tqdm(dataloader['test'])\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"B3SBPmNFk648","outputId":"21c40609-89c7-49bd-d74c-489285970e80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678301686681,"user_tz":240,"elapsed":96933,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["loss 0.63741 acc 0.81626: 100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n","val_loss 0.19486 val_acc 0.94510: 100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5 loss 0.63741 val_loss 0.19486 acc 0.81626 val_acc 0.94510\n"]},{"output_type":"stream","name":"stderr","text":["loss 0.14042 acc 0.95904: 100%|██████████| 30/30 [00:15<00:00,  1.97it/s]\n","val_loss 0.08782 val_acc 0.97559: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/5 loss 0.14042 val_loss 0.08782 acc 0.95904 val_acc 0.97559\n"]},{"output_type":"stream","name":"stderr","text":["loss 0.08218 acc 0.97605: 100%|██████████| 30/30 [00:14<00:00,  2.00it/s]\n","val_loss 0.06772 val_acc 0.97823: 100%|██████████| 5/5 [00:02<00:00,  2.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/5 loss 0.08218 val_loss 0.06772 acc 0.97605 val_acc 0.97823\n"]},{"output_type":"stream","name":"stderr","text":["loss 0.05985 acc 0.98196: 100%|██████████| 30/30 [00:14<00:00,  2.00it/s]\n","val_loss 0.04853 val_acc 0.98445: 100%|██████████| 5/5 [00:02<00:00,  2.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/5 loss 0.05985 val_loss 0.04853 acc 0.98196 val_acc 0.98445\n"]},{"output_type":"stream","name":"stderr","text":["loss 0.04962 acc 0.98516: 100%|██████████| 30/30 [00:15<00:00,  1.98it/s]\n","val_loss 0.04495 val_acc 0.98542: 100%|██████████| 5/5 [00:02<00:00,  2.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/5 loss 0.04962 val_loss 0.04495 acc 0.98516 val_acc 0.98542\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model = CNN()\n","fit(model, dataloader)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"N0h5rb4Bk648","executionInfo":{"status":"ok","timestamp":1678301697518,"user_tz":240,"elapsed":2,"user":{"displayName":"Jhon Erick Ramirez leaños","userId":"18410470016893431508"}}},"outputs":[],"source":["# guardar modelo\n","\n","PATH = './checkpoint.pt'\n","torch.save(model.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"g1qv3A9Ck648"},"source":["Ahora podemos cargar nuestro modelo y utilizarlo normalmente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqNqQtWgk649","outputId":"c059e776-e9cb-4e7b-c459-0d483523f59a"},"outputs":[{"data":{"text/plain":["CNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# cargar modelo\n","\n","model.load_state_dict(torch.load(PATH))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSia7nqrk649"},"outputs":[],"source":["def evaluate(model, dataloader): \n","    model.eval()\n","    model.to(device)\n","    bar = tqdm(dataloader['test'])\n","    acc = []\n","    with torch.no_grad():\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.to(device), y.to(device)\n","            y_hat = model(X)\n","            acc.append((y == torch.argmax(y_hat, axis=1)).sum().item() / len(y))\n","            bar.set_description(f\"acc {np.mean(acc):.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KonnG1Rzk649","outputId":"3b1d154f-e0e1-4b8c-ecc4-0a7b7fd632d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98639: 100%|██████████| 5/5 [00:01<00:00,  4.34it/s]\n"]}],"source":["evaluate(model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"rwuA_SqYk649"},"source":["Si bien de esta manera podemos guardar y cargar el modelo de manera eficiente, necesitamos tener un modelo instanciado para poder llamar a la función `model.load_state_dict()`. Esto significa que necesitaremos la definición de nuestro modelo allá dónde queramos importarlo (lo cual es poco flexible). Alternativamente, `Pytorch` nos permite guardar el modelo entero, y no solo el `state_dict`, de la siguiente manera."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCyL2qx2k649"},"outputs":[],"source":["torch.save(model, 'model.pt')"]},{"cell_type":"markdown","metadata":{"id":"ILsljMOQk649"},"source":["Y podemos cargar y evaluar nuestro modelo así"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpyQuZZBk649","outputId":"592e1227-52d1-47de-f3b1-b423882e2ee7"},"outputs":[{"data":{"text/plain":["CNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.load('model.pt')\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWNE9yMpk64-","outputId":"87b12c9e-2df5-40af-910c-4bc534201672"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  4.69it/s]\n"]}],"source":["evaluate(model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"C-BQZ_4gk64-"},"source":["Si bien de esta forma no necesitamos que nuestro modelo esté instanciado, seguimos necesitando su definición. Es por este motivo que la opción anterior es la recomendada, ya que es más eficiente (sólo guardamos los pesos) y también más flexible (podemos guardar otra información además del `state_dict` de nuestro modelo). Esta opción es ideal para guardar y cargar modelos durante el entrenamiento del mismo, quizás incluso junto al estado del optimizador, de manera que podemos entrenar modelos a partir de estos `checkpoints` en lugar de empezar de cero cada vez. Otro ejemplo consistiría en guardar el `state_dict` del modelo durante el entrenamiento solo cuando mejore una métrica determinada y cargar el mejor modelo al final del entrenamiento (que no tiene porqué coincidir con el último).\n","\n","> ⚡ Aprende más sobre el guardado de modelos en `Pytorch` [aquí](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcRoU5Qdk64-"},"outputs":[],"source":["def fit(model, dataloader, epochs=5, PATH=\"./checkpoint.pt\"):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    best_acc = 0\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","        bar = tqdm(dataloader['test'])\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","        # guardar modelo si es el mejor\n","        val_acc = np.mean(val_acc)\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            torch.save(model.state_dict(), PATH)\n","            print(f\"Best model saved at epoch {epoch} with val_acc {val_acc:.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")\n","    # cargar el mejor modelo al final del entrenamiento\n","    model.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbGpvav8k64-","outputId":"c44e6636-cadb-4a38-caaa-3d7ce9d65373"},"outputs":[{"name":"stderr","output_type":"stream","text":["loss 0.58207 acc 0.82621: 100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n","val_loss 0.17891 val_acc 0.94974: 100%|██████████| 5/5 [00:01<00:00,  4.38it/s]\n","  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Best model saved at epoch 1 with val_acc 0.94974\n","Epoch 1/5 loss 0.58207 val_loss 0.17891 acc 0.82621 val_acc 0.94974\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.13597 acc 0.96013: 100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n","val_loss 0.08804 val_acc 0.97444: 100%|██████████| 5/5 [00:01<00:00,  4.36it/s]\n","  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Best model saved at epoch 2 with val_acc 0.97444\n","Epoch 2/5 loss 0.13597 val_loss 0.08804 acc 0.96013 val_acc 0.97444\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.08168 acc 0.97642: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]\n","val_loss 0.06352 val_acc 0.98124: 100%|██████████| 5/5 [00:01<00:00,  4.37it/s]\n","  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Best model saved at epoch 3 with val_acc 0.98124\n","Epoch 3/5 loss 0.08168 val_loss 0.06352 acc 0.97642 val_acc 0.98124\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.06125 acc 0.98203: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]\n","val_loss 0.04724 val_acc 0.98474: 100%|██████████| 5/5 [00:01<00:00,  4.33it/s]\n","  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Best model saved at epoch 4 with val_acc 0.98474\n","Epoch 4/5 loss 0.06125 val_loss 0.04724 acc 0.98203 val_acc 0.98474\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.05294 acc 0.98442: 100%|██████████| 30/30 [00:07<00:00,  3.85it/s]\n","val_loss 0.04511 val_acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  4.14it/s]"]},{"name":"stdout","output_type":"stream","text":["Best model saved at epoch 5 with val_acc 0.98524\n","Epoch 5/5 loss 0.05294 val_loss 0.04511 acc 0.98442 val_acc 0.98524\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model = CNN()\n","fit(model, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9ShWe4Ok64_","outputId":"800352b6-d83a-41b5-8f1d-f97ab89c91ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  4.36it/s]\n"]}],"source":["evaluate(model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"nek0-lIrk64_"},"source":["Guardar nuestros modelos, ya sea el modelo entero o solo su `state_dict`, es la forma más directa y sencilla de guardar cualquier modelo que hagamos. Sin embargo, tiene ciertas limitaciones. Por un lado, como ya hemos visto, necesitamos la definición del modelo tanto a la hora de entrar como en producción. Esto no solo es engorroso y poco flexible, si no que sólo funcionará en entornos `Python` con `Pytorch` instalado. Si bien ésto es suficiente para, por ejemplo, poner nuestros modelos a trabajar en un servidor [Flask](https://sensioai.com/blog/052_produccion)), en muchas ocasiones necesitaremos ejecutar nuestras redes neuronales en otros entornos (smartphones, aplicaciones web, IoT, ...) en las que usaremos otros lenguajes de programación. Para ello, `Pytorch` nos permite `exportar` nuestro modelo en vez de simplemente `guradarlo`."]},{"cell_type":"markdown","metadata":{"id":"_KN7mv1pk64_"},"source":["## Exportando modelos"]},{"cell_type":"markdown","metadata":{"id":"w2MsbPcWk64_"},"source":["### Torchscript"]},{"cell_type":"markdown","metadata":{"id":"6nSy18Ugk64_"},"source":["[Torchscript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html) es una representación intermedia de un modelo de `Pytorch` que puede ejecutarse en diferentes entornos sin la necesidad de `Python`, por ejemplo en `C++`. Un modelo de `Pytorch` exportado en `torchscript` contiene los pesos de la red así como su definición (todas las operaciones que aplicaremos a un tensor desde la entrada hasta la salida). Tenemos dos maneras de exportar un modelo con `torchscript`: \n","\n","- `tracing`: Dada un entrada, se genera una representación del modelo de manera dinámica registrando todas las operaciones aplicadas al tensor hasta la salida. En este caso no seremos capaces de capturar diferentes caminos en nuestra red (*control flow*). Es la alternativa más eficiente, pero menos flexible.\n","- `scripting`: Genera la representación intermedia de nuestra red neuronal directamente a partir del análisis de la misma, siendo capaz de capturar de manera fiel cualquier ramificación en la misma. No es tan eficiente, pero si más flexible."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr4pzk9-k64_"},"outputs":[],"source":["# tracing\n","\n","x = torch.rand(32, 1, 28, 28)\n","traced_model = torch.jit.trace(model.cpu(), x)\n","traced_model.save('model.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSnZQ7wOk64_","outputId":"418f4e55-ab1f-4372-ccfc-ed536853e8c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  4.38it/s]\n"]}],"source":["loaded_model = torch.jit.load('model.zip')\n","evaluate(loaded_model, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRkafmlWk65A"},"outputs":[],"source":["# scripting\n","\n","scripted_model = torch.jit.script(model.cpu())\n","scripted_model.save('model.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4UeNk3nk65A","outputId":"ba8ee027-f2cd-4435-e346-912ce2530eba"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  4.42it/s]\n"]}],"source":["loaded_model = torch.jit.load('model.zip')\n","evaluate(loaded_model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"FpaNboS2k65A"},"source":["Exportar nuestro modelo nos aporta varias ventajas:\n","\n","- Ahora nuestro modelo puede ejecutarse en cualquier entorno capaz de interpretar la representación intermedia generada por `torchscript`, independientemente del hardware o software utilizado.\n","- Nuestro modelo contiene los pesos y la definición de las operaciones, evitando tener que guardar código extra.\n","- Esta representación intermedia puede ser optimizada de manera independiente, haciendo que nuestros modelos sean más rápidos. \n","\n","La principal desventaja es que al estar \"traduciendo\" `Python` a otro lenguaje, es posible que no todas las operaciones que queramos hacer estén soportadas."]},{"cell_type":"markdown","metadata":{"id":"58rOHBXwk65A"},"source":["> ⚡ Aprende más sobre `Torchscript`[aquí](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)."]},{"cell_type":"markdown","metadata":{"id":"-wdRwHzhk65A"},"source":["Un consejo a tener en cuenta a la hora de exportar nuestros modelos que nos puede hacer la vida más fácil cuando pongamos nuestros modelos en producción, es incluir cualquier pre- o post-procesado de datos necesarios en el mismo modelo. Durante el entrenamiento no lo hacemos por motivos de eficiencia (queremos que nuestra `GPU` entrene la red lo más rápido posible mientras la `CPU` procesa cada batch de datos de manera paralela), pero estos procesados pueden ser costosos en producción (a veces incluso imposibles de realizar) por lo que incluirlos en el modelo es generalmente una buena idea.\n","\n","En este caso incluimos la normalización y preparación de los datos en un pre-procesado y calculamos una distribución de probabilidad sobre las salida con un post-procesado, que además también nos devuelve la clase con mayor probabilidad."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXG538DTk65A"},"outputs":[],"source":["class Preprocessing(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","    def forward(self, x):\n","        # esperamos un batch de imágenes sin normalizar\n","        # normalización\n","        x = (x / 255.)\n","        x = (x - 0.1307) / 0.3081\n","        # dimsensiones -> [bs, c, h, w]\n","        x = x.unsqueeze(1)\n","        # en imágenes en color, haríamos un `permute`\n","        return x\n","    \n","class Postprocessing(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__() \n","        self.softmax = torch.nn.Softmax(dim=1)\n","    def forward(self, x) :\n","        # devolvemos distribución de probabilidad \n","        # y clase con mayor probabilidad\n","        return self.softmax(x), torch.argmax(x, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mi3ypWyk65B"},"outputs":[],"source":["final_model = torch.nn.Sequential(\n","    Preprocessing(),\n","    model.cpu(),\n","    Postprocessing()\n",")\n","\n","scripted_model = torch.jit.script(final_model)\n","scripted_model.save('model.zip')"]},{"cell_type":"markdown","metadata":{"id":"c8AWwm8qk65B"},"source":["Ahora nuestro modelo acepta lotes de imágenes sin normalizar y con las dimensiones más comunes (alto, ancho) y devuelve una distribución de probabilidad. Es nuestro modelo quien se encarga del procesado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lpMZEUck65B"},"outputs":[],"source":["def script_evaluate(model, dataloader): \n","    model = torch.jit.load(model)\n","    model.eval()\n","    bar = tqdm(dataloader['test'])\n","    acc = []\n","    with torch.no_grad():\n","        for batch in bar:\n","            X, y = batch\n","            # desnormalizar\n","            X = (X*0.3081 + 0.1307)*255\n","            # quitar dimensión canales\n","            X = X.squeeze(1)\n","            # el modelo pre-procesa\n","            y_hat, label = model(X)\n","            acc.append((y == label).sum().item() / len(y))\n","            bar.set_description(f\"acc {np.mean(acc):.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oWAcIWrk65B","outputId":"df321419-21fe-469e-a829-4ebdd23c5799"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"]}],"source":["script_evaluate(\"model.zip\", dataloader)"]},{"cell_type":"markdown","metadata":{"id":"r2Gcl4sEk65B"},"source":["### ONNX"]},{"cell_type":"markdown","metadata":{"id":"5brZLUE8k65B"},"source":["Si bien ahora nuestro modelo es capaz de ser importado y ejecutado de forma más flexible y eficiente, seguimos limitados por el hecho de necesitar `Pytorch` (o la librería `Torchscript` en `C++`) para ello. Por este motivo, `Pytorch` nos ofrece una última manera de exportar nuestros modelos a otra forma de representación intermedia conocida como [ONNX](https://onnx.ai/). Éste es un formato abierto con el espíritu de convertirse en un estándar de representación de redes neuronales. La gran mayoría de librerías y *frameworks* de `deep learning` soportan este formato, lo que implica que, por ejemplo, podemos entrenar un modelo en `Pytorch`, exportarlo en formato `ONNX` e importarlo en `Tensorflow` para ponerlo en producción (aunque `ONNX` también ofrece soluciones optimizadas para ello: `ONNX Runtime`). Así pues, exportar nuestros modelos a formato `ONNX` nos proporcionará la máxima flexibilidad, permitiéndonos, entre muchas otras cosas, ejecutar nuestras redes neuronales en entornos tales como navegadores web o IoT. Por contra, esta librería es la menos flexible en cuanto a cantidad y tipo de operaciones que podemos exportar, lo cual puede imponer unas restricciones muy grandes sobre nuestros modelos (aunque cada vez se soportan más)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfP6Sz82k65B"},"outputs":[],"source":["x = torch.rand(32, 1, 28, 28)\n","y = model.cpu()(x)\n","\n","# exportamos el modelo\n","torch.onnx.export(model,                     # el modelo\n","                  x,                         # un ejemplo del input\n","                  \"model.onnx\",              # el nombre del archivo para guardar el modelo\n","                  export_params=True,        # guardar los pesos de la red\n","                  opset_version=10,          # versión de ONNX\n","                  do_constant_folding=True,  # optimizaciones\n","                  input_names = ['input'],   # nombre de los inputs\n","                  output_names = ['output'], # nombre de los outputs\n","                  dynamic_axes={'input' : {0 : 'batch_size'},    # ejes con longitud variable (para poder usar diferentes tamaños de batch)\n","                                'output' : {0 : 'batch_size'}})"]},{"cell_type":"markdown","metadata":{"id":"5CSKda8pk65B"},"source":["Para poder ejecutar nuestro modelo necesitamos la librería de `ONNX Runtime` para `Python`, que puedes instalar con el comando `pip install onnxruntime`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijFsVvt3k65B"},"outputs":[],"source":["import onnxruntime\n","\n","def onnx_evaluate(model, dataloader): \n","    # cargarmos el modelo\n","    ort_session = onnxruntime.InferenceSession(model)\n","    bar = tqdm(dataloader['test'])\n","    acc = []\n","    with torch.no_grad():\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.numpy(), y.numpy()\n","            # generamos los inputs\n","            ort_inputs = {ort_session.get_inputs()[0].name: X}\n","            # extraemos los outputs\n","            ort_outs = ort_session.run(None, ort_inputs)[0]\n","            acc.append((y == np.argmax(ort_outs, axis=1)).mean())\n","            bar.set_description(f\"acc {np.mean(acc):.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6sv3Dozk65B","outputId":"ae17e394-e69c-4c93-a28b-0460b98c064b"},"outputs":[{"name":"stderr","output_type":"stream","text":["acc 0.98524: 100%|██████████| 5/5 [00:01<00:00,  3.50it/s]\n"]}],"source":["onnx_evaluate(\"model.onnx\", dataloader)"]},{"cell_type":"markdown","metadata":{"id":"PCwdUD8tk65B"},"source":["De nuevo, te recomiendo incluir tanto pre- como post-procesado como parte del modelo para evitar problemas más adelante."]},{"cell_type":"markdown","metadata":{"id":"_SII_efck65B"},"source":["> ⚡ Aprende más sobre `ONNX`[aquí](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)."]},{"cell_type":"markdown","metadata":{"id":"LAaOMeJ9k65C"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"shG9SYtTk65C"},"source":["En este post hemos visto las diferentes manera que `Pytorch` nos ofrece a la hora de guardar y exportar nuestros modelos. Si en nuestro entorno de producción podemos usar `Python` e instalar `Pytorch`, entonces podemos simplemente `guardar` el `state_dict` de nuestro modelo, o incluso el modelo completo, y luego cargarlo en la aplicación. Ten en cuenta que necesitarás la definición de tu red neuronal (en nuestro ejemplo, la clase `Model`) que define las capas y operaciones que se aplican dada una entrada. Sin embargo, una opción más eficiente, consiste en `exportar` nuestro modelo con `torch.jit.trace` o `torch.jit.script` ya que luego podremos cargar nuestro modelos sin necesidad de arrastrar código y, además, podremos ejecutarlo en otros entornos como `C++`. Por último, si no puedes usar `Python` en tu aplicación, es muy posible que puedas usar `ONNX`, un formato estándar al que `Pytorch` nos permite también exportar."]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/054_pytorch_save/pytorch_save.ipynb","timestamp":1677647399754}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b93f5c7df2444090bfeb743ddbbf3ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3915d1941ec34b41b37b774737941fd4","IPY_MODEL_d0df0e2b45554cce9f4362498e346a53","IPY_MODEL_e5e88f4ba889485485af91ef0281f025"],"layout":"IPY_MODEL_5a95aca3df444c668e5d04a1980de689"}},"3915d1941ec34b41b37b774737941fd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_691e399985bf4792a3d48fb019292b08","placeholder":"​","style":"IPY_MODEL_ec25cd0f29074671b804132807bec6be","value":"100%"}},"d0df0e2b45554cce9f4362498e346a53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_310c76f184c84ab78c5d43412bf0a840","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cb4dc1fe90f4f2597c5e7e20a71fd6c","value":9912422}},"e5e88f4ba889485485af91ef0281f025":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd3c0f687e87446584a6b238e87c9fc8","placeholder":"​","style":"IPY_MODEL_d5ad3707c4984df2920c2edc9006ff4f","value":" 9912422/9912422 [00:00&lt;00:00, 32668800.36it/s]"}},"5a95aca3df444c668e5d04a1980de689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"691e399985bf4792a3d48fb019292b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec25cd0f29074671b804132807bec6be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"310c76f184c84ab78c5d43412bf0a840":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb4dc1fe90f4f2597c5e7e20a71fd6c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd3c0f687e87446584a6b238e87c9fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ad3707c4984df2920c2edc9006ff4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d16cb0d205a4b44b88d24a8d01966cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c94a2b7b36794e239392f74bfff37515","IPY_MODEL_1c86f865fcbd40a5b64d1eef1654ebec","IPY_MODEL_241e348a98a947fe9fae9b16dcae5ca6"],"layout":"IPY_MODEL_64e7983f7b2b47879fb557e958a0d03f"}},"c94a2b7b36794e239392f74bfff37515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b035fb6e5e7841a4a81dfa479c5e8260","placeholder":"​","style":"IPY_MODEL_fd245234912d4158b585d09d7ace1740","value":"100%"}},"1c86f865fcbd40a5b64d1eef1654ebec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5556b81b8d5473f80fb9b25238e171b","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd0515fc5fc043d684946214652f2472","value":28881}},"241e348a98a947fe9fae9b16dcae5ca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bc3c16df03e498fa406784851aeb591","placeholder":"​","style":"IPY_MODEL_650ae2c78d4e4bb99d22e13dc0be97f4","value":" 28881/28881 [00:00&lt;00:00, 2097079.39it/s]"}},"64e7983f7b2b47879fb557e958a0d03f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b035fb6e5e7841a4a81dfa479c5e8260":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd245234912d4158b585d09d7ace1740":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5556b81b8d5473f80fb9b25238e171b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0515fc5fc043d684946214652f2472":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0bc3c16df03e498fa406784851aeb591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"650ae2c78d4e4bb99d22e13dc0be97f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7e41746d3e84ec28444cc6a6cf459bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d368b9a233624fc79239669f0a15120a","IPY_MODEL_a2b54c7c3edf4a36831302f7dea7345a","IPY_MODEL_a3fe87b624dd4883b5ca3944bb048ddf"],"layout":"IPY_MODEL_c124a1fbccce42e5a75c156698a02044"}},"d368b9a233624fc79239669f0a15120a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34df469c068a483b94a897e4ec85c034","placeholder":"​","style":"IPY_MODEL_e901ddfd4b9c4d13802377c61ade63b2","value":"100%"}},"a2b54c7c3edf4a36831302f7dea7345a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_431f621c1cb948efbcc8efc0a5d27811","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95dd4dc4a1254bd3bc29e5053bd85574","value":1648877}},"a3fe87b624dd4883b5ca3944bb048ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f02074f2e54e43dca1d21a96d12a5c88","placeholder":"​","style":"IPY_MODEL_7c46ac524d2f46ca88e362551eb24b0e","value":" 1648877/1648877 [00:00&lt;00:00, 6527094.57it/s]"}},"c124a1fbccce42e5a75c156698a02044":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34df469c068a483b94a897e4ec85c034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e901ddfd4b9c4d13802377c61ade63b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"431f621c1cb948efbcc8efc0a5d27811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95dd4dc4a1254bd3bc29e5053bd85574":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f02074f2e54e43dca1d21a96d12a5c88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c46ac524d2f46ca88e362551eb24b0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccd9379b10374ce487d4d4e281c95cd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b53dc7c0083142d0a8d80d2a7cc29bca","IPY_MODEL_669eafef82c547858ef880b17e668ed8","IPY_MODEL_f34ad34c90244d238f98513fbba5f76e"],"layout":"IPY_MODEL_93ba84c075144a64a1a513dd372bd752"}},"b53dc7c0083142d0a8d80d2a7cc29bca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8464eb1c31b44b08acf2375260fb4e6","placeholder":"​","style":"IPY_MODEL_6f640510e32a4559a61c939130fd1324","value":"100%"}},"669eafef82c547858ef880b17e668ed8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcd8b6d4979d4d60901e87f873f85a3e","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25b5e4e4cd964ea59ecbb3673713dc31","value":4542}},"f34ad34c90244d238f98513fbba5f76e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c739f662c0884d46bd1c7d56168501d6","placeholder":"​","style":"IPY_MODEL_582badc8f3864563b8f18c3b239483dc","value":" 4542/4542 [00:00&lt;00:00, 335899.30it/s]"}},"93ba84c075144a64a1a513dd372bd752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8464eb1c31b44b08acf2375260fb4e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f640510e32a4559a61c939130fd1324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcd8b6d4979d4d60901e87f873f85a3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25b5e4e4cd964ea59ecbb3673713dc31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c739f662c0884d46bd1c7d56168501d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"582badc8f3864563b8f18c3b239483dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}